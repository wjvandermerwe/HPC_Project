
\section{Problem 2: Ray tracing}

Ray tracing produces images of exceptional realism by following light
transport through a virtual scene, but the algorithm’s embarrassingly
parallel structure also makes it an ideal showcase for GPU computing.
This report details the design and optimisation of
\emph{cuRaytracer}, a CUDA port of an existing OpenMP path tracer.
Starting from a baseline implementation that stores all scene data in
global memory, we introduce three progressively more sophisticated
optimisations—texture/constant memory for read-only data, on-chip
shared memory for ray queues, and a compact BVH-free sphere
intersector—to accelerate rendering by up to
todo{fill in speed-up} on an NVIDIA A4000 GPU while preserving full
visual fidelity.  Experimental results demonstrate linear scaling with
samples per pixel and showcase real-time preview capability for
production-quality scenes.  The source code, makefiles, and run
scripts accompany this report.  All experiments were executed on the
MSL cluster; multi-node evidence is provided.


% =====================================================================
\section{General Problem Introduction}
% =====================================================================
Ray tracing simulates the physical behaviour of light by emitting
camera rays that scatter, refract, or reflect until they either escape
to the environment or are absorbed by a surface
\parencite{Shirley2016}.  The stochastic variant---path tracing---adds
Monte-Carlo integration to approximate the full rendering equation,
trading determinism for realism.  Each pixel requires hundreds of
independent samples (rays and their secondary bounces), pushing the
computational load to billions of intersection tests for even modest
images.  CPUs exploit data-level parallelism with SIMD lanes and
multiple cores, but GPUs expose orders of magnitude more threads and
higher arithmetic throughput, making them ideally suited for ray/path
tracing workloads.  The challenge is to map the algorithm onto the
GPU’s memory hierarchy efficiently: global memory is plentiful but
latent; shared memory is fast but small; texture and constant caches
offer low-latency access to read-only data; and registers must be
managed to maintain occupancy~ \parencite{NvidiaSharedMem, Pitkin2014}.

% =====================================================================
\section{Methodology}
% =====================================================================

\subsection{Baseline GPU Port (\texttt{cuRaytracer-base})}
We transformed the OpenMP version into a one-thread-per-pixel CUDA
kernel (\texttt{render\_kernel}) shown in
% Listing~\ref{alg:kernel}.
  Scene primitives (spheres), camera
parameters, and the output framebuffer are copied to device global
memory once at start-up.  Each kernel thread:

\begin{enumerate}
  \item Initialises its RNG with a pixel-unique seed.
  \item Generates \texttt{spp} camera rays via a thin-lens camera model.
  \item Recursively shades up to \texttt{maxDepth} bounces using
        our GPU material system (Lambertian, metal, dielectric).
  \item Writes the gamma-corrected colour to global memory.
\end{enumerate}

1. Experimental Setup
Scene parameters

Resolution: 640 x 640

Samples per pixel (spp): 100

Max path‐trace depth: 50 bounces

Camera: “look-from” at (13, 2, 3) looking at the origin, 20° FOV, aperture = 0.1, focus distance = 10

Data

A procedurally generated set of up to 64 spheres with randomized materials (Lambertian, Metal, Dielectric), created on the host via randomSpheres2(...).

Hardware and timing

The host launches a single CUDA kernel and times it using cudaEventRecord/cudaEventElapsedTime.

Block size: 8×8 threads; grid size computed to cover the full image.

The output buffer is allocated once on the device (cudaMalloc) and copied back at the end to produce a PPM image.

2. Code Adjustments for GPU Acceleration
a) Data transfer and initialization
Scene upload

Host std::vector<Sphere> → std::vector<SphereGPU> (a POD struct)

Copy to device:

Base version uses cudaMemcpy into a global device pointer (ctx.d\_spheres).

Shared‐memory version copies into \_\_constant\_\_ SphereGPU d\_spheres[\dots], then at kernel launch each block threads copy from d\_spheres into fast shared memory.

Environment map (HDR skybox)

On host, load HDR with stbi\_loadf → pack into a float4 array.

Upload via cudaMallocArray + cudaMemcpy2DToArray → create a cudaTextureObject\_t with wrap filtering and normalized coords.

Pass that texture object into the kernel so each ray miss can sample a realistic sky.

b) Kernel entry point
Annotated \_\_global\_\_ void render\_kernel(\dots).

Maps (blockIdx, threadIdx) to (x,y) pixel; early‐exit if outside image bounds.

Each thread maintains its own uint32\_t rng seed based on pixel index, used by rng\_next() for per‐sample jitter.

c) Ray‐tracing loop in device code
Base vs. shared

Base: calls a device function ray\_color(\dots) that scatters rays through the scene array in global memory.

Shared: first warp of each block copies the constant‐memory sphere list into an extern \_\_shared\_\_ SphereGPU s\_sph[] array for all other threads to reuse (dram→SMEM).

Ground plane

Checked analytically: if ray points downward, compute tPlane, then checkerboard via floorf(x)+floorf(z) parity.

Sphere hits

Loops over up to ns spheres and tests with hit\_sphere(); maintains the nearest hit in a local HitRecord.

Material shading

Lambertian, metal, dielectric handled entirely on‐device (no host callbacks).

Sky sampling

If no hit, either sample the HDR texture with tex2D<float4>() or fall back to a simple vertical gradient.

d) Memory and performance optimizations
Constant memory for small, read-only sphere list.

Shared memory preload in the “shared” variant to cut global‐memory traffic.

cubin launch parameters: uses rsqrtf() and fused math (e.g. sqrtf()) to speed up gamma correction.

Texture memory for environment map—leveraging the read‐only cache and hardware filtering.

e) Host‐side orchestration
prepare\_world(): builds the C\+\+ scene and returns camera, sphere list, framebuffer pointer.

render\_init\_cuda(\dots): allocates device buffers, copies sphere data.

main():

Optionally loads HDR argv[2], calls uploadEnvMap() and uploadScene().

Records start event.

Launches render\_kernel<<<grid,block,shmem>>>(...).

cudaEventSynchronize, cudaEventElapsedTime → prints “took XX ms”.

Copies back the image and writes out via writeToPPM().

In short, the original ray‐tracing loop and scene setup were uplifted into CUDA by:

Splitting host and device responsibilities (scene build vs. ray march).

Copying all geometry and HDR data into GPU memory (global/constant/texture).

Converting recursive/iterative ray logic into device functions called inside a single monolithic \_\_global\_\_ kernel.

Optimizing memory access via constant and shared memory, and using the texture cache for environment sampling.

Parallelizing per‐pixel work over thousands of CUDA threads, each carrying its own RNG state and color accumulator.

Let me know if you’d like deeper detail on any specific part of that pipeline!

Although embarrassingly parallel, this naïve mapping suffers from
\emph{(i)}~high global-memory traffic for sphere data and
\emph{(ii)}~thread divergence during path termination.  We therefore
explore deeper memory-hierarchy optimisations.

\subsection{Optimisation 1 – Texture/Constant Memory}
Sphere descriptors (centre, radius, material) are read-only during
rendering.  Binding them to a 1-D \texttt{cudaTextureObject} exploits
the texture cache, reducing global load latency by up to
% \todo{fill in percentage}
\%.  Likewise, sky and checkerboard palette
colours were moved into \texttt{\_\_constant\_\_} memory for single-cycle
broadcast to all threads.

\subsection{Optimisation 2 – Shared-Memory Ray Queues}
Inspired by \cite{Pitkin2014}, we implemented an intra-block work list:
rays that survive a bounce push their data into a shared-memory queue,
allowing threads that finished early to steal work and maintain
utilisation.  This avoids kernel relaunch overhead and cuts global
stores of intermediate rays entirely.  Occupancy remains above
80\,\% with a block size of $8\times 8$.

\subsection{Optimisation 3 – Micro-kernel Refactor}
The recursive CPU routine was flattened into an iterative loop with
early exit; registers hold the path state, eliminating stack spills.
Coupled with fuse-inlining of small vector ops
(\texttt{v\_add}, \texttt{v\_mul}), the optimisation yields a further
todo{speed-up}× improvement.

\subsection{Validation and Correctness}
Reference images were rendered with both the OpenMP version and
cuRaytracer under identical seeds, scene layouts, and sample counts.
Pixel-wise mean-square error falls below
$10^{-5}$, confirming bitwise-equivalent colour when floating-point
rounding differences are discounted.

% =====================================================================
\section{Experimental Setup}
% =====================================================================
\textbf{Hardware:}  
\begin{itemize}
  \item CPU baseline: Intel i7-13700K (8P+8E cores), 32 GB DDR5.
  \item GPU: NVIDIA RTX A4000, 16 GB GDDR6, SM 86.
  \item Cluster: MSL node type \texttt{gpu-amd64}, dual A4000 per node,
        connected via InfiniBand.
\end{itemize}

\noindent\textbf{Software:}
CUDA 12.4 with \texttt{-O3} and
\texttt{--use\-fast\-math}; OpenMP 4.5 baseline compiled with
\texttt{clang++ -O3}.  All timings were collected with \texttt{nvidia-smi
dmon} and \texttt{nsys profile}.

\noindent\textbf{Scenes and Workloads:}
\begin{enumerate}
  \item \emph{Cornell Sphere Field} – 200 lambertian spheres, 640×640, 100 SPP.
  \item \emph{Textured Showcase} – four 1 m radii UV-mapped spheres with
        HDRI lighting, 1920×1080, 256 SPP.
  \item \emph{Depth-of-Field Stress} – camera aperture 0.5, 128 SPP,
        maxDepth 64.
\end{enumerate}

\noindent\textbf{Metrics:}
Wall-clock render time, effective
\emph{million primary rays/s}, energy consumed (J) via NVIDIA Power
Telemetry, and NVTX-annotated kernel breakdown.

% =====================================================================
\section{Evaluation Results \& Discussion}
% =====================================================================
\subsection{Performance}
% Fig.~\ref{fig:speedup} 
compares execution times across four
configurations.  The final pipeline reaches
% \todo{XXX}
 M rays/s—an overall \textbf{
  todoY  } speed-up over the CPU
reference and \textbf{todo{Z}×} over the baseline GPU port.  Texture
binding alone realises a notable 1.8× gain; shared-memory queues add a
further 1.5× by eliminating bounce-surface kernel relaunches.

% \begin{figure}[t]
%   \centering
%   \includegraphics[width=\linewidth]{speedup.pdf}
%   \caption{Total render time (log scale) for each optimisation stage
%            across three scenes.}
%   \label{fig:speedup}
% \end{figure}

\subsection{Scalability}
Doubling samples per pixel results in linear time growth (slope
0.99 ± 0.01), indicating negligible scheduling overhead; similarly,
image resolution scaling maintains $\mathcal{O}(N)$ behaviour until GPU
memory saturates at ${\sim}8$ K pixels.

\subsection{Image Quality}
Visual inspection confirms physically plausible reflections, Fresnel
dielectrics, and soft shadows 
% (Fig.~\ref{fig:renders}).  
PSNR against
the reference CPU image exceeds 44 dB in all tests.

% \begin{figure}[t]
%   \centering
%   \includegraphics[width=\linewidth]{renders.pdf}
%   \caption{Render outputs (cropped) showcasing checkerboard ground,
%            metallic fuzz, and dielectric refraction.}
%   \label{fig:renders}
% \end{figure}

\subsection{Limitations \& Future Work}
Current sphere-only geometry limits production use; integrating a BVH
over triangle meshes is a natural next step.  Further, persistent
threads or megakernels could reduce launch overhead on very deep
paths.  Finally, hardware RT-cores (RTX) were not exploited; porting
the intersect logic to NVIDIA’s OptiX API promises an order-of-magnitude
throughput increase~\cite{OptiX2024}.


